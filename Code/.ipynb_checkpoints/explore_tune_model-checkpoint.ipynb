{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import seaborn as sns\n",
    "import scipy.sparse \n",
    "\n",
    "import sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet, ElasticNetCV\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgbm\n",
    "\n",
    "sys.path.insert(1, './')\n",
    "import Utility\n",
    "import imp\n",
    "#imp.reload(Utility)  \n",
    "from Utility import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy 1.18.1\n",
      "pandas 1.0.1\n",
      "sklearn 0.22.1\n",
      "lightgbm 2.3.1\n"
     ]
    }
   ],
   "source": [
    "for p in [np, pd, sklearn, lgbm]:\n",
    "    print (p.__name__, p.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this file, we load cleaned training data, train model, and save model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_hdf('../CleanData/trainDF.h5', 'df')\n",
    "valid_df = pd.read_hdf('../CleanData/validDF.h5', 'df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5068102 entries, 4488710 to 9556811\n",
      "Data columns (total 49 columns):\n",
      " #   Column                       Dtype  \n",
      "---  ------                       -----  \n",
      " 0   shop_id                      int8   \n",
      " 1   item_id                      int16  \n",
      " 2   date_block_num               int8   \n",
      " 3   avg_item_price               float32\n",
      " 4   target                       float32\n",
      " 5   target_shop                  float32\n",
      " 6   target_item                  float32\n",
      " 7   item_category_id             int8   \n",
      " 8   target_item_category         float32\n",
      " 9   avg_item_price_lag_1         float32\n",
      " 10  target_lag_1                 float32\n",
      " 11  target_shop_lag_1            float32\n",
      " 12  target_item_lag_1            float32\n",
      " 13  target_item_category_lag_1   float32\n",
      " 14  avg_item_price_lag_2         float32\n",
      " 15  target_lag_2                 float32\n",
      " 16  target_shop_lag_2            float32\n",
      " 17  target_item_lag_2            float32\n",
      " 18  target_item_category_lag_2   float32\n",
      " 19  avg_item_price_lag_3         float32\n",
      " 20  target_lag_3                 float32\n",
      " 21  target_shop_lag_3            float32\n",
      " 22  target_item_lag_3            float32\n",
      " 23  target_item_category_lag_3   float32\n",
      " 24  avg_item_price_lag_4         float32\n",
      " 25  target_lag_4                 float32\n",
      " 26  target_shop_lag_4            float32\n",
      " 27  target_item_lag_4            float32\n",
      " 28  target_item_category_lag_4   float32\n",
      " 29  avg_item_price_lag_5         float32\n",
      " 30  target_lag_5                 float32\n",
      " 31  target_shop_lag_5            float32\n",
      " 32  target_item_lag_5            float32\n",
      " 33  target_item_category_lag_5   float32\n",
      " 34  avg_item_price_lag_6         float32\n",
      " 35  target_lag_6                 float32\n",
      " 36  target_shop_lag_6            float32\n",
      " 37  target_item_lag_6            float32\n",
      " 38  target_item_category_lag_6   float32\n",
      " 39  avg_item_price_lag_12        float32\n",
      " 40  target_lag_12                float32\n",
      " 41  target_shop_lag_12           float32\n",
      " 42  target_item_lag_12           float32\n",
      " 43  target_item_category_lag_12  float32\n",
      " 44  month                        int8   \n",
      " 45  shop_mean                    float64\n",
      " 46  item_mean                    float64\n",
      " 47  shop_item_mean               float64\n",
      " 48  item_category_mean           float64\n",
      "dtypes: float32(40), float64(4), int16(1), int8(4)\n",
      "memory usage: 995.7 MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1356992 entries, 9556812 to 10913803\n",
      "Data columns (total 49 columns):\n",
      " #   Column                       Non-Null Count    Dtype  \n",
      "---  ------                       --------------    -----  \n",
      " 0   shop_id                      1356992 non-null  int8   \n",
      " 1   item_id                      1356992 non-null  int16  \n",
      " 2   date_block_num               1356992 non-null  int8   \n",
      " 3   avg_item_price               1356992 non-null  float32\n",
      " 4   target                       1356992 non-null  float32\n",
      " 5   target_shop                  1356992 non-null  float32\n",
      " 6   target_item                  1356992 non-null  float32\n",
      " 7   item_category_id             1356992 non-null  int8   \n",
      " 8   target_item_category         1356992 non-null  float32\n",
      " 9   avg_item_price_lag_1         1356992 non-null  float32\n",
      " 10  target_lag_1                 1356992 non-null  float32\n",
      " 11  target_shop_lag_1            1356992 non-null  float32\n",
      " 12  target_item_lag_1            1356992 non-null  float32\n",
      " 13  target_item_category_lag_1   1356992 non-null  float32\n",
      " 14  avg_item_price_lag_2         1356992 non-null  float32\n",
      " 15  target_lag_2                 1356992 non-null  float32\n",
      " 16  target_shop_lag_2            1356992 non-null  float32\n",
      " 17  target_item_lag_2            1356992 non-null  float32\n",
      " 18  target_item_category_lag_2   1356992 non-null  float32\n",
      " 19  avg_item_price_lag_3         1356992 non-null  float32\n",
      " 20  target_lag_3                 1356992 non-null  float32\n",
      " 21  target_shop_lag_3            1356992 non-null  float32\n",
      " 22  target_item_lag_3            1356992 non-null  float32\n",
      " 23  target_item_category_lag_3   1356992 non-null  float32\n",
      " 24  avg_item_price_lag_4         1356992 non-null  float32\n",
      " 25  target_lag_4                 1356992 non-null  float32\n",
      " 26  target_shop_lag_4            1356992 non-null  float32\n",
      " 27  target_item_lag_4            1356992 non-null  float32\n",
      " 28  target_item_category_lag_4   1356992 non-null  float32\n",
      " 29  avg_item_price_lag_5         1356992 non-null  float32\n",
      " 30  target_lag_5                 1356992 non-null  float32\n",
      " 31  target_shop_lag_5            1356992 non-null  float32\n",
      " 32  target_item_lag_5            1356992 non-null  float32\n",
      " 33  target_item_category_lag_5   1356992 non-null  float32\n",
      " 34  avg_item_price_lag_6         1356992 non-null  float32\n",
      " 35  target_lag_6                 1356992 non-null  float32\n",
      " 36  target_shop_lag_6            1356992 non-null  float32\n",
      " 37  target_item_lag_6            1356992 non-null  float32\n",
      " 38  target_item_category_lag_6   1356992 non-null  float32\n",
      " 39  avg_item_price_lag_12        1356992 non-null  float32\n",
      " 40  target_lag_12                1356992 non-null  float32\n",
      " 41  target_shop_lag_12           1356992 non-null  float32\n",
      " 42  target_item_lag_12           1356992 non-null  float32\n",
      " 43  target_item_category_lag_12  1356992 non-null  float32\n",
      " 44  month                        1356992 non-null  int8   \n",
      " 45  shop_mean                    1356992 non-null  float64\n",
      " 46  item_mean                    1356992 non-null  float64\n",
      " 47  shop_item_mean               1356992 non-null  float64\n",
      " 48  item_category_mean           1356992 non-null  float64\n",
      "dtypes: float32(40), float64(4), int16(1), int8(4)\n",
      "memory usage: 266.6 MB\n"
     ]
    }
   ],
   "source": [
    "valid_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = train_df['target']\n",
    "Y_valid = valid_df['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttrain's rmse: 1.11494\tvalid's rmse: 1.00755\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's rmse: 1.04573\tvalid's rmse: 0.951846\n",
      "[3]\ttrain's rmse: 0.99807\tvalid's rmse: 0.915016\n",
      "[4]\ttrain's rmse: 0.964546\tvalid's rmse: 0.888932\n",
      "[5]\ttrain's rmse: 0.922858\tvalid's rmse: 0.858541\n",
      "[6]\ttrain's rmse: 0.90596\tvalid's rmse: 0.846599\n",
      "[7]\ttrain's rmse: 0.879031\tvalid's rmse: 0.826928\n",
      "[8]\ttrain's rmse: 0.863188\tvalid's rmse: 0.813086\n",
      "[9]\ttrain's rmse: 0.851892\tvalid's rmse: 0.806566\n",
      "[10]\ttrain's rmse: 0.844632\tvalid's rmse: 0.801526\n",
      "[11]\ttrain's rmse: 0.837195\tvalid's rmse: 0.797549\n",
      "[12]\ttrain's rmse: 0.831354\tvalid's rmse: 0.795516\n",
      "[13]\ttrain's rmse: 0.82845\tvalid's rmse: 0.793538\n",
      "[14]\ttrain's rmse: 0.82494\tvalid's rmse: 0.792379\n",
      "[15]\ttrain's rmse: 0.822125\tvalid's rmse: 0.792038\n",
      "[16]\ttrain's rmse: 0.81999\tvalid's rmse: 0.790611\n",
      "[17]\ttrain's rmse: 0.812984\tvalid's rmse: 0.786412\n",
      "[18]\ttrain's rmse: 0.811198\tvalid's rmse: 0.785757\n",
      "[19]\ttrain's rmse: 0.808072\tvalid's rmse: 0.784959\n",
      "[20]\ttrain's rmse: 0.803964\tvalid's rmse: 0.782797\n",
      "[21]\ttrain's rmse: 0.802006\tvalid's rmse: 0.782657\n",
      "[22]\ttrain's rmse: 0.800934\tvalid's rmse: 0.782106\n",
      "[23]\ttrain's rmse: 0.799148\tvalid's rmse: 0.782136\n",
      "[24]\ttrain's rmse: 0.796945\tvalid's rmse: 0.780638\n",
      "[25]\ttrain's rmse: 0.793379\tvalid's rmse: 0.778258\n",
      "[26]\ttrain's rmse: 0.791923\tvalid's rmse: 0.778024\n",
      "[27]\ttrain's rmse: 0.790582\tvalid's rmse: 0.777669\n",
      "[28]\ttrain's rmse: 0.787704\tvalid's rmse: 0.775931\n",
      "[29]\ttrain's rmse: 0.786819\tvalid's rmse: 0.77576\n",
      "[30]\ttrain's rmse: 0.785894\tvalid's rmse: 0.77569\n",
      "[31]\ttrain's rmse: 0.784938\tvalid's rmse: 0.775264\n",
      "[32]\ttrain's rmse: 0.783736\tvalid's rmse: 0.774298\n",
      "[33]\ttrain's rmse: 0.78277\tvalid's rmse: 0.773949\n",
      "[34]\ttrain's rmse: 0.781047\tvalid's rmse: 0.773378\n",
      "[35]\ttrain's rmse: 0.780268\tvalid's rmse: 0.773384\n",
      "[36]\ttrain's rmse: 0.779306\tvalid's rmse: 0.774033\n",
      "[37]\ttrain's rmse: 0.778642\tvalid's rmse: 0.77366\n",
      "[38]\ttrain's rmse: 0.777933\tvalid's rmse: 0.773536\n",
      "[39]\ttrain's rmse: 0.777454\tvalid's rmse: 0.773443\n",
      "[40]\ttrain's rmse: 0.776926\tvalid's rmse: 0.773279\n",
      "[41]\ttrain's rmse: 0.776009\tvalid's rmse: 0.773255\n",
      "[42]\ttrain's rmse: 0.775577\tvalid's rmse: 0.773314\n",
      "[43]\ttrain's rmse: 0.774821\tvalid's rmse: 0.773109\n",
      "[44]\ttrain's rmse: 0.773978\tvalid's rmse: 0.772962\n",
      "[45]\ttrain's rmse: 0.773293\tvalid's rmse: 0.772897\n",
      "[46]\ttrain's rmse: 0.771781\tvalid's rmse: 0.772359\n",
      "[47]\ttrain's rmse: 0.770423\tvalid's rmse: 0.771777\n",
      "[48]\ttrain's rmse: 0.769396\tvalid's rmse: 0.771798\n",
      "[49]\ttrain's rmse: 0.768716\tvalid's rmse: 0.771817\n",
      "[50]\ttrain's rmse: 0.766378\tvalid's rmse: 0.770653\n",
      "[51]\ttrain's rmse: 0.765621\tvalid's rmse: 0.770679\n",
      "[52]\ttrain's rmse: 0.765136\tvalid's rmse: 0.7706\n",
      "[53]\ttrain's rmse: 0.764466\tvalid's rmse: 0.770498\n",
      "[54]\ttrain's rmse: 0.763842\tvalid's rmse: 0.770677\n",
      "[55]\ttrain's rmse: 0.76294\tvalid's rmse: 0.770612\n",
      "[56]\ttrain's rmse: 0.762567\tvalid's rmse: 0.77062\n",
      "[57]\ttrain's rmse: 0.762143\tvalid's rmse: 0.77044\n",
      "[58]\ttrain's rmse: 0.761503\tvalid's rmse: 0.770791\n",
      "[59]\ttrain's rmse: 0.761113\tvalid's rmse: 0.770752\n",
      "[60]\ttrain's rmse: 0.760766\tvalid's rmse: 0.770753\n",
      "[61]\ttrain's rmse: 0.760175\tvalid's rmse: 0.770398\n",
      "[62]\ttrain's rmse: 0.759811\tvalid's rmse: 0.770563\n",
      "[63]\ttrain's rmse: 0.759061\tvalid's rmse: 0.770287\n",
      "[64]\ttrain's rmse: 0.758508\tvalid's rmse: 0.769978\n",
      "[65]\ttrain's rmse: 0.757854\tvalid's rmse: 0.769222\n",
      "[66]\ttrain's rmse: 0.757517\tvalid's rmse: 0.769096\n",
      "[67]\ttrain's rmse: 0.757202\tvalid's rmse: 0.769036\n",
      "[68]\ttrain's rmse: 0.756352\tvalid's rmse: 0.769543\n",
      "[69]\ttrain's rmse: 0.756007\tvalid's rmse: 0.769298\n",
      "[70]\ttrain's rmse: 0.755596\tvalid's rmse: 0.769213\n",
      "[71]\ttrain's rmse: 0.75496\tvalid's rmse: 0.769224\n",
      "[72]\ttrain's rmse: 0.754589\tvalid's rmse: 0.769133\n",
      "[73]\ttrain's rmse: 0.753936\tvalid's rmse: 0.769059\n",
      "[74]\ttrain's rmse: 0.753627\tvalid's rmse: 0.76905\n",
      "[75]\ttrain's rmse: 0.753341\tvalid's rmse: 0.768943\n",
      "[76]\ttrain's rmse: 0.751838\tvalid's rmse: 0.767425\n",
      "[77]\ttrain's rmse: 0.751429\tvalid's rmse: 0.767408\n",
      "[78]\ttrain's rmse: 0.751125\tvalid's rmse: 0.767344\n",
      "[79]\ttrain's rmse: 0.750522\tvalid's rmse: 0.767081\n",
      "[80]\ttrain's rmse: 0.750081\tvalid's rmse: 0.767587\n",
      "[81]\ttrain's rmse: 0.749864\tvalid's rmse: 0.767541\n",
      "[82]\ttrain's rmse: 0.749478\tvalid's rmse: 0.767288\n",
      "[83]\ttrain's rmse: 0.749169\tvalid's rmse: 0.767201\n",
      "[84]\ttrain's rmse: 0.748873\tvalid's rmse: 0.76705\n",
      "[85]\ttrain's rmse: 0.748616\tvalid's rmse: 0.766912\n",
      "[86]\ttrain's rmse: 0.748338\tvalid's rmse: 0.766854\n",
      "[87]\ttrain's rmse: 0.747889\tvalid's rmse: 0.766728\n",
      "[88]\ttrain's rmse: 0.747483\tvalid's rmse: 0.766657\n",
      "[89]\ttrain's rmse: 0.7472\tvalid's rmse: 0.766592\n",
      "[90]\ttrain's rmse: 0.74616\tvalid's rmse: 0.765608\n",
      "[91]\ttrain's rmse: 0.745324\tvalid's rmse: 0.765181\n",
      "[92]\ttrain's rmse: 0.745009\tvalid's rmse: 0.765346\n",
      "[93]\ttrain's rmse: 0.744746\tvalid's rmse: 0.76537\n",
      "[94]\ttrain's rmse: 0.743957\tvalid's rmse: 0.764244\n",
      "[95]\ttrain's rmse: 0.742856\tvalid's rmse: 0.76339\n",
      "[96]\ttrain's rmse: 0.742497\tvalid's rmse: 0.763352\n",
      "[97]\ttrain's rmse: 0.742243\tvalid's rmse: 0.763317\n",
      "[98]\ttrain's rmse: 0.742002\tvalid's rmse: 0.763244\n",
      "[99]\ttrain's rmse: 0.741712\tvalid's rmse: 0.763275\n",
      "[100]\ttrain's rmse: 0.741075\tvalid's rmse: 0.762549\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's rmse: 0.741075\tvalid's rmse: 0.762549\n",
      "54.17863583564758\n"
     ]
    }
   ],
   "source": [
    "lgbm_features = ['avg_item_price_lag_1', 'target_lag_1', 'target_shop_lag_1', 'target_item_lag_1', \n",
    "                 'target_item_category_lag_1', 'avg_item_price_lag_2', 'target_lag_2', 'target_shop_lag_2',\n",
    "                 'target_item_lag_2', 'target_item_category_lag_2', 'avg_item_price_lag_3', 'target_lag_3', \n",
    "                 'target_shop_lag_3', 'target_item_lag_3', 'target_item_category_lag_3', 'avg_item_price_lag_4', \n",
    "                 'target_lag_4', 'target_shop_lag_4', 'target_item_lag_4', 'target_item_category_lag_4',\n",
    "                 'avg_item_price_lag_5', 'target_lag_5', 'target_shop_lag_5', 'target_item_lag_5', \n",
    "                 'target_item_category_lag_5', 'avg_item_price_lag_6', 'target_lag_6', 'target_shop_lag_6',\n",
    "                 'target_item_lag_6', 'target_item_category_lag_6', 'avg_item_price_lag_12', 'target_lag_12', \n",
    "                 'target_shop_lag_12', 'target_item_lag_12', 'target_item_category_lag_12', 'shop_mean',\n",
    "                 'item_mean', 'shop_item_mean', 'item_category_mean', 'month']\n",
    "lgbm_train_data = lgbm.Dataset(train_df[lgbm_features], label=Y_train, feature_name=lgbm_features) #categorical_feature\n",
    "lgbm_valid_data = lgbm.Dataset(valid_df[lgbm_features], label=Y_valid, feature_name=lgbm_features)\n",
    "\n",
    "params = {'objective':'regression', 'metric':['rmse'], 'boosting_type':'gbdt', 'num_rounds':100, 'eta':0.2, \n",
    "          'max_depth':8, 'min_data_in_leaf':150, 'min_gain_to_split':0.01, \n",
    "          'feature_fraction':0.7, 'bagging_freq':0, 'bagging_fraction':1.0, 'lambda_l1':0,\n",
    "          'lambda_l2':0.001, 'early_stopping_round':20, 'verbosity':1}\n",
    "eval_metrics = {}\n",
    "start = time.time()\n",
    "lgbm_model= lgbm.train(params, lgbm_train_data, valid_sets=[lgbm_train_data, lgbm_valid_data],\n",
    "                       valid_names=['train', 'valid'], evals_result=eval_metrics, verbose_eval=True)\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deXxcdb3w8c931iyTPU2aNi1p6V5aulMWNQWEggoqqEXB5VHqAnr16lX0+ojyPF65Pnq5LiiicFEv0IuIiAqy2VBBlrZ0b+m+pemWpNnXmXyfP85JO00mSZPOJE3m+369zmvmnN85c36/TJtvfusRVcUYY4zpyjPUGTDGGHNusgBhjDEmJgsQxhhjYrIAYYwxJiYLEMYYY2KyAGGMMSYmCxDGGGNisgBhzBkQkX0i0iwiDSJyREQeEpGQm/aQiKiIXNflmv90j3/c3Q+IyA9FpNz9nL0ick8P9+jcfjqoBTUmigUIY87ce1Q1BMwB5gJfj0rbAXysc0dEfMAHgN1R53wdWAAsAjKAJcC6WPeI2m6PfzGMOTO+oc6AMcONqh4RkWdxAkWnPwE3i0iOqp4AlgIbcQJBp4XAH1S1wt3f527GnJOsBmFMP4lIMXANsCvqcAvwFLDM3f8o8Jsul74G/LOIfE5EZomIJDyzxpwFCxDGnLknRaQeOAgcA+7skv4b4KMikgW8A3iyS/r3gH8HPgKsAQ6JyMe6nPOkiNREbbfGvRTGnCELEMacufeqagZQCkwD8qMTVfVlYBTwTeDPqtrcJT2iqveq6qVANvBd4EERmd7lHtlR2y8TWB5jemUBwph+UtWXgIeAH8RI/m/gy3RvXur6Gc2qei9wApgR7zwaEw/WSW3MwPwnsE9E5nQ5/mPg78CqrheIyBeB9cDrQDtOU1MG3UcyGXNOsABhzACo6nER+Q3wv4H6qOPVwIs9XNYM/BCYBCjO0NgbVHVP1Dl/EpFI1P7zqvq+uGbemDMk9sAgY4wxsVgfhDHGmJgsQBhjjInJAoQxxpiYLEAYY4yJacSMYsrPz9eSkpIBX9/Y2Eh6enr8MjQMJGOZITnLnYxlhuQsd3/LvHbt2kpVHRUrbcQEiJKSEtasWTPg68vKyigtLY1fhoaBZCwzJGe5k7HMkJzl7m+ZRWR/T2nWxGSMMSYmCxDGGGNisgBhjDEmJgsQxhhjYrIAYYwxJiYLEMYYY2KyAGGMMSampA8QdS3t3PP8DvbURPo+2RhjkkjSBwjtgB+9uJOdNR1DnRVjjDmnJH2AyEz14fMI9W32XAxjjImW9AFCRMhND1BnAcIYY06T9AECIC8UtBqEMcZ0YQECyEsPUNdqAcIYY6IlLECIyIMickxENveQPk1EXhWRVhH5Spe0pSKyXUR2icgdicpjp7xQgPp2CxDGGBMtkTWIh4ClvaRXA18AfhB9UES8wL3ANcAM4CYRmZGgPAI4fRBWgzDGmNMkLECo6iqcINBT+jFVXQ20d0laBOxS1T2q2gasAK5PVD4B8kNBWiLQ0m5zIYwxptO5+MCgscDBqP1y4KJYJ4rIcmA5QGFhIWVlZQO64fFyJ0b95YWXyEtNnm6ZhoaGAf/MhrNkLHcylhmSs9zxLPO5GCAkxrGY7T+qej9wP8CCBQt0oE+OattyhIe2rGXq7PlcMDZrQJ8xHCXj07YgOcudjGWG5Cx3PMt8Lv65XA6Mi9ovBioSecO8UACAyobWRN7GGGOGlXMxQKwGJovIBBEJAMuApxJ5w7z0IADVjW2JvI0xxgwrCWtiEpFHgVIgX0TKgTsBP4Cq3icio4E1QCbQISJfBGaoap2I3A48C3iBB1V1S6LyCZDr1iCqGixAGGNMp4QFCFW9qY/0IzjNR7HSngaeTkS+YskI+vAJVFkNwhhjTjoXm5gGnYiQERCqrA/CGGNOsgDhygyK9UEYY0wUCxCuDL9QaQHCGGNOsgDhyghCdaM1MRljTCcLEK5Mv9goJmOMiWIBwpURFJraIjS32XpMxhgDFiBOygg4K3xUWTOTMcYAFiBOynQDhI1kMsYYhwUI18kahPVDGGMMYAHipM4ahC3YZ4wxDgsQrgxrYjLGmNNYgHCleCHo89h6TMYY47IA4RIR8tID1gdhjDEuCxBR8kJBG+ZqjDEuCxBRctMD1gdhjDEuCxBR8kLWxGSMMZ0sQETJSw9Q1diKqg51VowxZsglLECIyIMickxENveQLiLyYxHZJSIbRWReVFpERNa7W0KfRx0tLxSkpb2DJluPyRhjElqDeAhY2kv6NcBkd1sO/DwqrVlV57jbdYnL4uly051nU1s/hDHGJDBAqOoqoLqXU64HfqOO14BsESlKVH7ORH7ICRA2m9oYY4a2D2IscDBqv9w9BpAiImtE5DURee9gZSg3PQhYDcIYYwB8Q3hviXGss3d4vKpWiMhE4G8isklVd3f7AJHlOM1TFBYWUlZWNuDMNDQ0cHzTmwC8snYj3qP+AX/WcNHQ0HBWP7PhKhnLnYxlhuQsdzzLPJQBohwYF7VfDFQAqGrn6x4RKQPmAt0ChKreD9wPsGDBAi0tLR1wZsrKyrj8ksv4l1XPkl88gdLSSQP+rOGirKyMs/mZDVfJWO5kLDMkZ7njWeahbGJ6CvioO5ppMVCrqodFJEdEggAikg9cCmwdjAylBXxkpvg4UtsyGLczxphzWsJqECLyKFAK5ItIOXAn4AdQ1fuAp4FrgV1AE/AJ99LpwC9EpAMngN2tqoMSIADG5qRx6ETzYN3OGGPOWQkLEKp6Ux/pCtwW4/g/gFmJyldfxmancrC6aahub4wx5wybSd1FcU4qh2qabTa1MSbpWYDoYmx2Kg2tYeqaw0OdFWOMGVIWILoozkkFoLzGmpmMMcnNAkQXY90AYR3VxphkZwGii7HZbg3CAoQxJslZgOgiNz1Ait/DoRoLEMaY5GYBogsRodjmQhhjjAWIWMZmp1oNwhiT9CxAxDA2J5XyEzaKyRiT3CxAxDA2O5UTTe00tdlcCGNM8rIAEUOxDXU1xhgLELGcmixnAcIYk7wsQMQwNjsNsLkQxpjkZgEihoKMIH6vWBOTMSapWYCIweMRirJsqKsxJrlZgOhBcU4qh2yoqzEmiVmAaKyE/76BvMrVpx22yXLGmGRnAcKfCrteIL1x/2mHx+akcrSuldZwZIgyZowxQythAUJEHhSRYyKyuYd0EZEfi8guEdkoIvOi0j4mIjvd7WOJyiMAgXQIZhFoqz7tcOeqrodrWhJ6e2OMOVclsgbxELC0l/RrgMnuthz4OYCI5AJ3AhcBi4A7RSQngfmEzCKCrVWnHSrOcYa6WjOTMSZZJSxAqOoqoLqXU64HfqOO14BsESkCrgaeV9VqVT0BPE/vgebsZcQKEDab2hiT3HxDeO+xwMGo/XL3WE/HuxGR5Ti1DwoLCykrKxtQRqY2CdktladdH+5QBHh5/TYKGncP6HPPdQ0NDQP+mQ1nyVjuZCwzJGe541nmoQwQEuOY9nK8+0HV+4H7ARYsWKClpaUDy0lkFXqkjNK3vw083pOHi9f8jY70bEpL5/Vy8fBVVlbGgH9mw1gyljsZywzJWe54lnkoRzGVA+Oi9ouBil6OJ05GEUIHNB4/7fDUwgy2H6lP6K2NMeZcNZQB4ingo+5opsVAraoeBp4FrhKRHLdz+ir3WOJkjnFe606PQ1NHZ7C3stGGuhpjklLCmphE5FGgFMgXkXKckUl+AFW9D3gauBbYBTQBn3DTqkXk/wCdM9fuUtXeOrvPXkaR81p/+LTDUwozCHcoeysbmTY6M6FZMMaYc03CAoSq3tRHugK39ZD2IPBgIvIVUw8BojMobD9SbwHCGJN0bCY1QKgAxQN1pweICfnp+Dxi/RDGmKRkAQLA46UtkNOtBhHweZg4Kt0ChDEmKVmAcLUGc7t1UgNMHZ3J9qMWIIwxyccChKs1mAv1R7odn1oYovxEMw2t4SHIlTHGDB0LEK62QB7Ux65BAOywWoQxJslYgHC1BvOgpRbaTn9I0NTCDAB2WD+EMSbJWIBwtQZznTddOqqLc1JJC3h5ywKEMSbJWIBwtQViBwiPR5hcmGFNTMaYpGMBwtUazHPedJkLAU5HtQ11NcYkGwsQrpMBooeO6qrGNiobWgc5V8YYM3QsQLgivjQIhHoY6mod1caY5GMBIlrG6JiT5aaMDgFYR7UxJqlYgIiWUdStkxpgVChIbnrAOqqNMUnFAkS0zDExO6lFhIn56eytbByCTBljzNCwABEtY7RTg9DuTzgdn5fG/qqmGBcZY8zIZAEiWsYY6GiHpqpuSSV56Rypa6Gl3Z4uZ4xJDgl7YNCwlOk+OKiuAtLzT0s6Ly8NgAPVTUxxRzUZY4a39vZ2ysvLaWlpGeqsxE1WVhbbtm3rdjwlJYXi4mL8fv8Zf1ZCA4SILAV+BHiBX6nq3V3Sz8N5ctwooBq4WVXL3bQIsMk99YCqXpfIvAJODQKcZqai2aclleSlA7CvstEChDEjRHl5ORkZGZSUlCAiQ52duKivrycj4/TfUapKVVUV5eXlTJgw4Yw/K2FNTCLiBe4FrgFmADeJyIwup/0A+I2qzgbuAr4XldasqnPcLfHBAZw+CIg5kqmzBmH9EMaMHC0tLeTl5Y2Y4NATESEvL6/fNaVE9kEsAnap6h5VbQNWANd3OWcG8KL7fmWM9MGVMRrEA7Xl3ZKy0wJkpfrZX20jmYwZSUZ6cOg0kHImsolpLHAwar8cuKjLORuAG3Caod4HZIhInqpWASkisgYIA3er6pNdbyAiy4HlAIWFhZSVlQ04sw0NDZT9/RUWpRTSsO0fbPV0/6zcQIR1O8spK+veiT0cNTQ0nNXPbLhKxnInY5mh73JnZWVRXz9085tqamr43e9+x6233tqv62644QYeeOABsrOzu6VFIpEey9TS0tK/fweq2uMGXB71fkKXtPf3ce0HcPodOvdvAX7S5ZwxwBPAOpwgUQ5kdaa5rxOBfcD5vd1v/vz5ejZWrlzpvHn4g6r3XhzznNsfeVMv+/cXz+o+55KTZU4yyVjuZCyzat/l3rp16+BkpAd79+7VmTNndjseDocH/Jl1dXU9psUqL7BGe/i92lcT0w+i3v++S9o3+7i2HBgXtV8MnLaOhapWqOr7VXUu8K/usdrONPd1D1AGzO3jfvGRPxmqdkFH9+GsJXlpHDrRTFu4Y1CyYowZ2e644w52797NnDlzWLhwIUuWLOHDH/4ws2bNAuC9730v8+fPZ+bMmdx///0nryspKaGyspJ9+/Yxffp0br31VmbOnMlVV11Fc3Nz3PLXVxOT9PA+1n5Xq4HJIjIBOAQsAz582geI5APVqtoBfB1nRBMikgM0qWqre86lwPf7uF985E+FSCvU7IfciaclnZeXTofCoZpmJuSnD0p2jDGD4zt/2sLWirq4fuaMMZnc+Z6ZPabffffdbN68mfXr11NWVsa73vUuNm/efHKk0YMPPkhubi7Nzc0sXLiQG264gby8vNM+Y+fOnTz66KP88pe/5IMf/CB//OMf+91k1ZO+ahDaw/tY+6cnqoaB24FngW3AY6q6RUTuEpHOUUmlwHYR2QEUAt91j08H1ojIBpzO67tVdWtfhYmL/CnO6/Ed3ZJK3JFM+6qso9oYE3+LFi06bRjqj3/8Yy688EIWL17MwYMH2blzZ7drJkyYwJw5cwCYP38+Bw4ciFt++qpBTBSRp3BqC53vcff7HEyrqk8DT3c59q2o948Dj8e47h/ArL4+PyHyJzuvlTtg6tLTksZ3DnWtbISpg50xY0wi9faX/mBJTz/VMlFWVsYLL7zAq6++SlpaGqWlpTGHqQaDwZPvvV4v4XA4bvnpK0BEDzv9QZe0rvsjQ1oupI9yAkQXo0JB0gJe9lfbXAhjzNnLyMjoccRRbW0tOTk5pKWl8dZbb/Haa68Ncu76CBCq+lL0voj4gQuAQ6p6LJEZG1L5U2IGCBHhvLx0myxnjImLvLw8Lr30Ui644AJSU1MpLCw8mbZ06VLuu+8+Zs+ezdSpU1m8ePGg56/XACEi9+EMTd0iIlnAq0AEyBWRr6jqo4ORyUGXPwW2/MFZ1bXL5JKSvDS223MhjDFx8sgjj8Q8HgwGeeaZZ2Km7du3D4D8/Hw2b9588vhXvvKVuM7r6KuT+m2qusV9/wlgh6rOAuYDX41bLs41+VOgpQYaK7sljc9L42B1E5GOXvvojTFm2OsrQLRFvX8n8CSAqnZ/cPNI0jmSKUYzU0leOu0R5XBt/MYaG2PMuaivAFEjIu8Wkbk4cxH+CiAiPiA10ZkbMqN6DhC2aJ8xJln0FSA+jTOX4b+AL0bVHK4A/pLIjA2pzGLwp/UQINxlv20uhDFmhOtrFNMOYGmM48/iTIAbmTweyJsUM0AUZaYQ8Hk4YDUIY8wI19coph/3lq6qX4hvds4h+VPg4BvdDns8wvjcNHYfbxiCTBljzODpq4npM8BlOIvsrQHWdtlGrvwpUHsA2rrXFC6akMsru6poaovfjEVjjOlLKBQCoKKightvvDHmOddeey1r1qyJy/36ChBFwP3A1TjLdfuBp1T116r667jk4FzV2VFdtatb0nsuHENze4QXt43cuYLGmHPXmDFjePzxbqsUxV2vAUJVq1T1PlVdAnwcyAa2iMgtCc/ZUOtlqOuiklwKM4M8taGiW5oxxpypr33ta/zsZz87uf/tb3+b73znO1xxxRXMmzePWbNm8cc//rHbdfv27eOCCy4AoLm5mWXLljF79mw+9KEPDepy3wCIyDzgJpy5EM8w0puXAHLPdx4/enx7tySPR3j37DH89tX91Da3k5XqH4IMGmPi6pk74Mim+H7m6Flwzd09Ji9btowvfvGLfO5znwPgscce469//Stf+tKXyMzMpLKyksWLF3Pdddf1+MjQn//856SlpbFx40Y2btzIvHnz4pb9XmsQIvIdEVkL/DPwErBAVT85aEtvDyV/ilOLOLw+ZvJ7LhxDW6SD57aM7DmDxpjEmTt3LseOHaOiooINGzaQk5NDUVER3/jGN5g9ezZXXnklhw4d4ujRoz1+xqpVq7j55psBmD179smaRTz0VYP438Ae4EJ3+zc3igmgqjo7bjk5FxUvhLf+HHNNpguLsxiXm8qfNh7mAwvG9fABxphho5e/9BPpxhtv5PHHH+fIkSMsW7aMhx9+mOPHj7N27Vr8fj8lJSUxl/mO1lPt4mz1FSD6fObDiDZuEaz7rdNR3fmcCJeI8J7ZY/jFqj1UNbSSFwr28CHGGNOzZcuWceutt1JZWclLL73EY489RkFBAX6/n5UrV7J///5er3/729/Oww8/zJIlS9i8efNpi/edrb46qffH2nCeN31Z3HJxripe5LwefD1m8nsuHEOkQ3lmszUzGWMGZubMmdTX1zN27FiKior4yEc+wpo1a1iwYAEPP/ww06ZN6/X6z372szQ0NDB79my+//3vM3/+/Ljlra+JcpnAbcBY4CngeZylN74CrAcejltOzkX5UyAly5kwN/fmbsnTRmcwqSDE05sOc/Pi84Ygg8aYkWDTplOd4/n5+bz66qsxz2tocCbolpSUnKwppKamsmLFipPn1NfXk5GREZd89TUP4rc4D9fcBHwKeA64EbheVa/v7UIAEVkqIttFZJeI3BEj/TwReVFENopImYgUR6V9TER2utvH+lWqePF4YOwCKF8dM1lEuGxSPusO1BCOdAxy5owxJrH6ChATVfXjqvoLnGGuC4B3q2rsoT1RRMQL3AtcA8wAbhKRGV1O+wHwG7ez+y7ge+61ucCdwEXAIuBOEck582LF0bhFcGwbtNTGTJ47Ppvm9og9RMgYM+L0FSDaO9+oagTYq6pn+ptwEbBLVfeoahuwgtOfcQ1O4HjRfb8yKv1q4HlVrVbVEzhNW90WDRwUxQsBhUOxp37MHefErfUHawYxU8YYk3h9jWK6UETq3PcCpLr7ncNcM3u5dixwMGq/HKdGEG0DcAPwI+B9QIaI5PVw7diuNxCR5cBygMLCQsrKyvooTs8aGhpiXu8Nt3AZwr6/P8b+g93jqaqS4Ydn3niLsc17B3z/odBTmUe6ZCx3MpYZ+i53VlYWdXV1CRsmOhQikUjMx46qKi0tLf36d9DXct/efufulFg/8a7P6fwK8FMR+TiwCjgEhM/wWlT1fpy1oliwYIGWlpYOOLNlZWX0eP32aUzwHWdCD+kL96/mQHUTpaXvGPD9h0KvZR7BkrHcyVhm6Lvce/fupa2tjby8vBETJGJ1UqsqVVVVZGdnM3fu3DP+rDNaamOAyoHoGWTFOKvCnqSqFcD7AUQkBNygqrUiUg6Udrm2LIF57d24hbD1j9DR4XRcdzF3XDYrtx+jrqWdzBRbdsOY4aK4uJjy8nKOHz8+1FmJm5aWFlJSUrodT0lJobi4OMYVPUtkgFgNTBaRCTg1g2XAh6NPEJF8oFpVO4CvAw+6Sc/izNru7Ji+yk0fGuMugjd/A1U7YdTUbslzxmejChsP1nLZ5PwhyKAxZiD8fj8TJoys+cBlZWX9qiX0pq9O6gFT1TDOnIlngW3AY6q6RUTuEpHr3NNKge0isgMoBL7rXlsN/B+cILMauMs9NjROTpjr/gAhgNnF2QCsO3BisHJkjDEJl8gaBKr6NPB0l2Pfinr/OBBzUXNVfZBTNYqhlTcJUrKh/A2Y132l86xUP5MKQjaSyRgzoiSsBjGieDwwZg4c3tDjKXPGZbP+YA2q3frSjTFmWLIAcaZGz3YmzEXaYybPGZdNVWMb5Sfi97AOY4wZShYgzlTRhRBpg+NvxUyeO97ph3jT+iGMMSOEBYgzNdp99MXhjTGTpxZmkOr3Wj+EMWbEsABxpvLOB38aHIkdIHxeD7PGZvHmAQsQxpiRwQLEmfJ4ofCCHmsQAJdOymdjeQ0VNdYPYYwZ/ixA9EfRbOeh5h2xl/Z+39yxqMKT6w8NcsaMMSb+LED0x+jZ0FYPJ2Ivyjc+L42FJTk88eYhG+5qjBn2LED0R5HbUd1DPwTA++cVs+tYA5sOxX5+hDHGDBcWIPqjYAZ4fL32Q1w7q4iAz8MTb1ozkzFmeLMA0R++IIya1msNIivVzztnFPLUhgrawvYYUmPM8GUBor9Gz+61BgFww7yxVDe28dKOkbOEsDEm+ViA6K+i2dB4DOqP9HjK2yaPIj8U4Ik3ywcxY8YYE18WIPqrjxnVAH6vh/fOGcvzW49ysLppkDJmjDHxZQGiv0bPcl6P9LyyK8Ctb5+I1yP86MWdg5ApY4yJPwsQ/ZWSCTkToHxNr6cVZqZwy+LzeOLNcvYcbxikzBljTPxYgBiIGdfDzuegclevp32m9HxS/F7+8wWrRRhjhp+EBggRWSoi20Vkl4jcESN9vIisFJF1IrJRRK51j5eISLOIrHe3+xKZz367+HbwBuHl/+j1tPxQkE9cWsKfNlbw1pG6QcqcMcbER8IChIh4gXuBa4AZwE0iMqPLad/EeVb1XGAZ8LOotN2qOsfdPpOofA5IaBQs+ARsWAEn9vV66q1vm0go4OM/ntsxOHkzxpg4SWQNYhGwS1X3qGobsAK4vss5CmS677OAigTmJ74u+byzwuvL9/R6WnZagE+/YyLPbT1qw16NMcOKJGpRORG5EViqqp9y928BLlLV26POKQKeA3KAdOBKVV0rIiXAFmAHUAd8U1X/HuMey4HlAIWFhfNXrFgx4Pw2NDQQCoX6dc3kHfdRdPh5Xr/oPlpTRvV4XqRD+cGaFnbVdPCvF6VQkuUdcD7jaSBlHgmSsdzJWGZIznL3t8xLlixZq6oLYiaqakI24APAr6L2bwF+0uWcfwa+7L6/GNiKU6sJAnnu8fnAQSCzt/vNnz9fz8bKlSv7f9GJ/arfyVX9y7/0eWplfYte8r0X9eJ/e0GP17f0/14JMKAyjwDJWO5kLLNqcpa7v2UG1mgPv1cT2cRUDoyL2i+mexPSJ4HHAFT1VSAFyFfVVlWtco+vBXYDUxKY14HJHg8z3gubfgcdkV5PzQsF+cUt86lqbOO2h9+kPWLrNBljzm2JDBCrgckiMkFEAjid0E91OecAcAWAiEzHCRDHRWSU28mNiEwEJgN7EpjXgZv2Lmiu7nNeBMAFY7O4+4ZZvL63mn9/5q1ByJwxxgxcwgKEqoaB24FngW04o5W2iMhdInKde9qXgVtFZAPwKPBxt8rzdmCje/xx4DOqWp2ovJ6V8y93lgDf8dczOv19c4v5+CUl/Orlvfx54/DpkzfGJB9fIj9cVZ8Gnu5y7FtR77cCl8a47vfA7xOZt7hJzYbxFzsT566884wu+ca109l0qJavPr6RKYUZTCnMSHAmjTGm/2wmdTxMuRqOboaag2d0esDn4WcfmUdawMdnfruWE41tCc6gMcb0nwWIeJh8tfO689kzvqQwM4V7PzyX8ppmbn7gdWqaLEgYY84tFiDiIX+ys4Dfjuf6ddlFE/O4/5b57DzawEd+ZUHCGHNusQARDyIwZSnsfQna+vf8h9KpBfzio06QuPmB19l1rD5BmTTGmP6xABEvU66CcAvsXdXvS5dMLeAXt8xn7/FG3nnPKr7w6DoLFMaYIWcBIl7OuxQCoX71Q0RbMq2Av3/tcj7zjvN5YdtR3nnPKv71D5us2ckYM2QsQMSLLwjnL4G3/gKR9gF9RG56gK8tncbLX7ucj19SworVB7n8hy/x2OqDdHQkZs0sY4zpiQWIeJp7CzQchW1/OquPyU0PcOd7ZvLnz1/G+aPS+ervN3LVf67iD+vKCdsSHcaYQWIBIp4mXQk5JfDGL+PycdOLMnns0xfzk5vm4hXhS/+zgct/+BK/XLWHY3UtcbmHMcb0xAJEPHm8sOCTcOAfcGRzXD5SRHjPhWN45p/exv23zCc/FOC7T29j8fde5GMPvsHWCntSnTEmMSxAxNvcm8GXAqvjU4vo5PEIV80czROfu5QXv/wOPlc6iS0VtXz0wTeoqGmO672MMQYsQMRfWi7MuhE2PgbNNQm5xfmjQnzl6qk8eutiWtoj3PqbNTS1hRNyL2NM8rIAkQgLb4X2Jlj/SEJvM7kwg5/cNJdthw0wq20AABn4SURBVOv48mMbbKSTMSauLEAkwpg5ULwIXv95wmoRnZZMK+Ab107nmc1H+Nh/vcH/rD5AZUNrQu9pjEkOFiAS5cpvQ91hWPERaE/siKNPXjaBf7l6KnuON/K1329i4Xdf4H89tJpth60D2xgzcBYgEqXkUnjffbD/ZfjDp6EjcfMXRITblkzi5a8t4ekvvI3PL5nEmn3VXPvjv/PP/7Oe8hP9Wx/KGGPAAkRizboRrvq/sPVJ+OsdoIntIxARZozJ5J+vmsrfv3o5y98+kb9sOszV96zid2sOogm+vzFmZLEAkWgX3w6Lb4M3fgFPfhbCg7O2Ulaan69fM50Xv/wOLhibxb88vpHbHnnT1nYyxpyxhAYIEVkqIttFZJeI3BEjfbyIrBSRdSKyUUSujUr7unvddhG5OpH5TCgRuPq7sOSbsOFR+O/3Q/OJQbt9cU4aj9y6mK8tncZzW45yyd1/4/OPruPZLUdoi1iNwhjTs4Q9k1pEvMC9wDuBcmC1iDzlPoe60zeBx1T15yIyA+f51SXu+2XATGAM8IKITFHVSKLym1Ai8I5/gezx8Mfb4IGr4IYHoGj2oNze6xE+W3o+75gyiv9+fT9/3XyEP22owCswedMqZhRlMrs4iyumFzIuN21Q8mSMOfclsgaxCNilqntUtQ1YAVzf5RwFMt33WUCF+/56YIWqtqrqXmCX+3nD24Ufgo8+CS218MvLYdUPIDJ4E9xmjMnk3943ize+cQW//eQilpb4GZ2Vwiu7K/n2n7bytu+v5Op7VvEfz21nb2XjoOXLGHNukkR1XIrIjcBSVf2Uu38LcJGq3h51ThHwHJADpANXqupaEfkp8Jqq/rd73gPAM6r6eJd7LAeWAxQWFs5fsWLFgPPb0NBAKBQa8PX94WuvY8qO+yg4/gp1GZM5NPbdVOYvIuIb3L/eo8t8rKmDdccivHk0zI4THSgwJcfD24t9XFzkw+uRQc1bIg3md32uSMYyQ3KWu79lXrJkyVpVXRArLWFNTECs3yhdo9FNwEOq+kMRuRj4rYhccIbXoqr3A/cDLFiwQEtLSwec2bKyMs7m+n5753Ww6XEyX/g2mW/dA75UmHK1M/Jp0jvBn5LwLHQt8wfd1yO1LTyxrpzH15Tzq02NvFqVwnffN4s547ITnqfBMOjf9TkgGcsMyVnueJY5kQGiHBgXtV/MqSakTp8ElgKo6qsikgLkn+G1w9+sG2Hm+6H8Ddj0O9jypDMkNpABU6+B8y6GojlQONN5INEgGZ2VwudKJ/HZd5zP05uOcNeft/C+n73CsoXjuO7Cscwdn02K3zto+THGDI1EBojVwGQRmQAcwul0/nCXcw4AVwAPich0IAU4DjwFPCIi/4HTST0ZeCOBeR06Hg+MX+xsS/8d9q2CzU84T6bb9Jh7jg9ScyCYASlZUHiB84jTkkudju8EERHeNbuIt0/J557nd/LrV/fx6BsHCfg8zBmXzcKSHBaU5DJvfA5Zqf6E5cMYMzQSFiBUNSwitwPPAl7gQVXdIiJ3AWtU9Sngy8AvReRLOE1IH1enU2SLiDwGbAXCwG3DdgRTf3h9cP7lznbdT6BmP1Ssc54t0VQFrXXQVO08sW7db51rpr3bOTctN2HZykjx8633zOCfrpzMmn3VvLanitf2VHPfS3uIrNyNR+Bds8fwhcsnMbkwI2H5MMYMrkTWIFDVp3GGrkYf+1bU+63ApT1c+13gu4nM3zlNxHk6XU4JzHzf6WkdHXBsK7z1Z2ck1M8vhfffDxPeltAsZaX6uWJ6IVdMLwSgsTXMhoM1rNx+jEdeP8CfN1Zw7QVFlE4dxcRRIc4flU52WiCheTLGJE5CA4RJEI8HRl/gbFOWwu8/Cb9+D5RcBlnFkDnWaXrKnQA5E5x9T/xHNKcHfVwyKZ9LJuXzudJJPPDyXn79j338ZdPhk+fkpQc4vyDEpIIQkwtCTC7IYHJhiIKMICIjZ2SUMSORBYjhbswcWP4SlH0PDr4Be/8O9YchukUuowhmfxAu/DAUTEtINnLSA3zl6qn805WTOVjdxJ7jjeypbGD3sUZ2HW/gLxsPU9vcfvL83PQAs8ZmcWFxFjPGZDGlMMT43DR8Xlv9xZhzhQWIkSAYcpbz6BQJQ90hOLEXqnbDzufhHz+FV37kBAtfELxB5rV2QMUkCBVAqjuEVTsgEHI6zcddBP7UfmXF7/UwcVSIiaNCQOHJ46pKZUMbO4/Vs/NoA1sqatlYXstPVx6n8zlHAZ+HmWMyuXxqAZdPL2BGUabVMowZQhYgRiKvD3LOc7aJpbDwk9BwDDY9Dke3QKQNIm2ED++HunI4tNaZ3S0CCERanUDhDcD4i53nbE+/7qzmZogIozKCjMoIcsn5+SePN7WF2Xm0gZ3HGth5tJ7X9lbzw+d38MPnd5CV6ue8vDTG56ZRkpfO5EKnqer8USEbZmvMILAAkSxCBXDx5047tLGnCTWt9bD/VWfI7Vt/gSduhbQ7YNYHnP4MfyoE0iGYCSmZzhDcUdPA2/+hrmkBHxeOy+bCqEl4x+tbWbn9GBsO1nCguolNh2p5ZvMRIlGPVM1LD1CUnUJRVirFOamMzXa2vFCQ3PQAeekBslL9eEbQDHBjBpsFCNNdMAOmXOVsV94Fe1+CNQ/A6l9BRw9rR6VkOTPAp1ztBBFfCvgCzhwO8YLH6zRdpeY4x3sxKiPIBxeM44MLTs2VbAt3sK+qkZ1HG9hzvIGK2hYO1zazv6qRf+yqpLGt+yhon0fICwUYlRGkJC+dSQVO01dFdYSiI/XkpPvJTw9aEDGmBxYgTO88Hjh/ibN1RKC9GdqboK3RmZfRUgcNR2H332DHs7D58b4/M5DhjLIaNRUKpjsjr07WRnIhY7TzGjXyKuAVpmS0M0WrILPWOTdlNAQzUG+A2lY4VNdOdVM71Y1tVDa0UdnQSmV9K0frW9lQXsNfNh0++cymu99Y5X6uh7E5Ti2kJC+dkvx0JuQ7zVpFWamkB+2/iEle9q/fnDmP1+kQD8ZYCGzWjc78jKObnOddhFudrSPs9Gd0hJ2mq+YTzqS/E/ug4k3Y8gdiLLMFHr8TBDp1BqYYBMh2Nzy+U5s34HbIByDooWO0EO5Qmpub8fu8dHR00KZemtsCNBz2UX/QS3PESxt+9uBhFx68Xi/e1ExCeWMZPWYcY8ZNwJc1BkKFTq0J3CcF6qknBvpTY/+MjBlmLECY+PF4oOjC/l3T1uTUQFrrnI7ypiqoPwoNR5zaSecoJl8KZI5xmq9Sspxg01LrXBdpd7aOdicQdYSdkVyRNgi3OK/agUeVAMqJY8fJGj0GxHPqnPYmNNJGuK2VttYWwu1thCMRIuEw3pYdZB18AV95x5kv+JI7EcbMhfypzs+lM3iI5/Qg5vE6r5F2N6+tgDjHxcNp61Z6/SdHoBFpdcrfUuuUVzwxzg84QTaYScHR3fDmQXcAgjrNfYF0J5AFMpxmxdRsSC9IyJwZMzxZgDBDK5DmTOgbRNvKyiiM0TkvgN/dujrR0MKbb+1mx57dHD64l5YTFaRrI4oQ9HvJC6WQleYnOzXA2JRWpukefAffgM2/T2xhxOsEAtRpAozWcWreyQyAbWfwed4gZI9zmv18qU5Q8vqd+4gbOJpPQONxaKp0gps/3ak1eQOnAl708OSTQdF7qj+q8/M6z+s8x+uHtHxn0ue4RYO6SKXpzgKEMWcgJ5TCFQtmcsWCmYCzzMi2w3VsO1LP9iN1bDreyOHaFg5VNNMW7iAtcBnXzxnLjReOYlJBBlmdS450RJxJjB1h531njccbPNUc1vnLXiOcqhGoc1641Wlu86U4tQN/2um/jKN1RE7WtF5/9WUuuuRtzn1EnD6ktgZobXBf3XW+ag44a4DVHnJqc501Me1w8qM4NY1QAeRNco61Nzuf1xF2akFdBzJ0NjFGwm7Z3bJpR1Re3XM62p0A9NLdToAqnBkVcMQNJB6nCTKQ5gQnX8DJe2Olk2fUDT5e5rW0w97RzrmdAawzqPoCzs/DG3ADYeegis57+E4d6wySpwU5j1PzGjUVssb1/D0MYxYgjBmA9KCPBSW5LCg5fZFEVWX9wRoeef0Af1hXzqNvHAAgI8VHcU4a+SFnCG5eKEhRVgpjslMZk51GUVYK+anB+D6YyeN1fpmnZtOctjehK//GVUst7HvFGT13/K1TgUTVeR9ug45GqKuA9kYnaKbmQnq+G1C8J4NS+9EKQJ15QJ3BuKOz+bHNaXLrbKKMtA48z4EQ5J0PaXlOXoIZTrALt0YFWHWCzaipMHq288jhczywWIAwJo5EhLnjc5g7PodvvnsGr+6u4mB1EwdPNHHoRDNVjW3sq2qksr6N5vbTm4S8HqHAHZI7cVQ6E0eFyA858zkyU/1kp/rJSQuQmeofUU/46yYlC6Zd62xnaVN/Hp6j7kCDzlpOZ42mM4CcrP10nKoFNZ9wgtixt6B6DzRXQ/Vep+bWWSP0Bk41p4VbYdtTp4KePw1yz3eaWQPpnKwlibib51Tzm3RODnXzmZLpBP3s8c6aaznnnfXPqysLEMYkSFaqn6UXjI6ZpqrUNrdTUePM5zhc28LRuhYqalrYW9nAnzZUUNcSe86JCOSlOzWQ0VkpbhDpDCQ+MlL8ZKb4yE0PUJiZQl66rah7Rjp/KePp36TP8y7p333ampwVDY5scJbCqdoNx7adGkDQWdvQjqgtEtXHJE7LY2v9qUAzZi4sL+tfPs6ABQhjhoCIkJ0WIDstwIwxmd3SVZXqxjZONLVR2xymrrmdmuY2apraOdHUzvF6J5jsr2pk3YEa6prbaYt0xLgTeATS/ZC/pozMFB856QGKc1IZl5NGcU4aBZlBCtxlUNIC9ish4QJpMG6hs52NSLvTzFZzgJhDxePA/jUYcw4SEfJCQfJCZzaKR1Vpbo9Q1xymvqWdupZ2qhvbOVrXwrG6Fjbu3EdGbhZ1ze0cr2/lzf0nYtZQslL9J2smmSl+MlJ8hFJ8ZKb4CQV9ZKT4GOeujZUfCthiikPJ6z+15lqCWIAwZgQQEdICPtICPkZndV9UsSxwmNLSuacdc5q4mjle38qx+laO1rVwxF3C5GhdK3srG6lvcQJOe6T7X6ihoNOMlZHiBI7s1ADZaX6y0vyMCgUpykpldFbKyXWxMlJ8tpz7MJPQACEiS4Ef4Txy9FeqeneX9HuAJe5uGlCgqtluWgTY5KYdUNXrEplXY5JNVqqfrFQ/04v6Prc1HKGhJUxtczsHqpvYW9nI/qomapraqG8JU9fSzt7KRmqa2zjR1E5bOHZzV3aan6KsVGfUVihAKOgnlOIjFPSSFvARCvooyAwyb3yOrdh7DkhYgBARL3Av8E6gHFgtIk+5jxkFQFW/FHX+54HoP3GaVXVOovJnjDlzQZ+XYMhLXijIxFEhSqf2fK6qUtccpqK2mSO1LVQ3tlHX0k5tczuVDa0crmmhoraFrRV1NLSGaWwLn5xo3ing9TDvvGzmjs8hL93pq8lO9ZMedIJIZqqPgowUUgMWRBIpkTWIRcAuVd0DICIrgOuBrT2cfxNwZwLzY4wZBCJCltvUNL2oewd8Vx0dSlN7hKbWMA2tYfZVNfLq7ipe2VXFL17aTUcv/a+ZKT4KMlPITQ+Qk+YMA04NeEnxe0n1ezla3s6JdeVkpfqd2oobYNKDXtKDPoI+j/Wj9EK0a+iO1weL3AgsVdVPufu3ABep6u0xzj0PeA0oVnWelSkiYWA9EAbuVtUnY1y3HFgOUFhYOH/FihUDzm9DQwOhUHItsJaMZYbkLPdwLXOHKs1haGxXGtuVljA0h5WmsFLTqpxocV4b2pz0hnZojShtEYjRbdKNVyDohRSfEPBCildO7qf5IeQXMgJCyC+ku1ua3zkvxQfpfiHoPbcCTH+/6yVLlqxV1QWx0hJZg4j1U+vpK1sGPN4ZHFzjVbVCRCYCfxORTaq6+7QPU70fuB9gwYIFesYTYmIo68+EmhEiGcsMyVnuZCxze6SDZ158iQvmLqS2uZ3G1ggNre3Ut4RpbA3T2BahoTVMU2uYpraIuznHG1vDlLe0U1PVTn1re4/3EIHzctOYNjqTKaMzmJDvjPAal5tGZoqfgG/wO+Xj+V0nMkCUA+Oi9ouBih7OXQbcFn1AVSvc1z0iUobTP7G7+6XGGNOd3+shMyDu89EHri3cQU1TG7XN7dQ0t1PX3H4yiByra2X70TreOlzPs1uPdO9L8XkIBX2kBbykB5whw2OyUzkvN43z8pzAMrnw3H2EbiIDxGpgsohMAA7hBIEPdz1JRKYCOcCrUcdygCZVbRWRfOBS4PsJzKsxxsQU8HkoyEyhILP3Z7K3hiMcrG5iX2UT5SeaaGgNU98apqElTHNbhMa2MPUtYdYfPMHTmw6ffISuzyOcPypEQWaQDHfOSbobVFIDXtL8zgivlICX9MCp0V65oQAFGUH8CRw6nLAAoaphEbkdeBZnmOuDqrpFRO4C1qjqU+6pNwEr9PTOkOnAL0SkA/Dg9EH01LltjDFDLujzMqkgg0kFGX2e2x7poPxEM9sO17G1oo63jtRR1dhGRU0zdS1us1d7pFuNpCsRGBUKctHEPH5y09zeTx6AhM6DUNWngae7HPtWl/1vx7juH8CsRObNGGOGit/rYUJ+OhPy07l2VuyJKKpKa7iDprYIze0RmtvCNLY6TVsNrWGqG9s4XOtMbszPSMx6WzaT2hhjzkEiQorfO6T9Ezbv3RhjTEwWIIwxxsRkAcIYY0xMFiCMMcbEZAHCGGNMTBYgjDHGxGQBwhhjTEwWIIwxxsSUsOW+B5uIHAf2n8VH5AOVccrOcJGMZYbkLHcylhmSs9z9LfN5qjoqVsKICRBnS0TW9LQm+kiVjGWG5Cx3MpYZkrPc8SyzNTEZY4yJyQKEMcaYmCxAnHL/UGdgCCRjmSE5y52MZYbkLHfcymx9EMYYY2KyGoQxxpiYLEAYY4yJKekDhIgsFZHtIrJLRO4Y6vwkioiME5GVIrJNRLaIyD+5x3NF5HkR2em+5gx1XuNNRLwisk5E/uzuTxCR190y/4+IJOZxXENIRLJF5HERecv9zi8e6d+1iHzJ/be9WUQeFZGUkfhdi8iDInJMRDZHHYv53Yrjx+7vt40iMq8/90rqACEiXuBe4BpgBnCTiMwY2lwlTBj4sqpOBxYDt7llvQN4UVUnAy+6+yPNPwHbovb/HbjHLfMJ4JNDkqvE+hHwV1WdBlyIU/4R+12LyFjgC8ACVb0A8ALLGJnf9UPA0i7HevpurwEmu9ty4Of9uVFSBwhgEbBLVfeoahuwArh+iPOUEKp6WFXfdN/X4/zCGItT3l+7p/0aeO/Q5DAxRKQYeBfwK3dfgMuBx91TRmKZM4G3Aw8AqGqbqtYwwr9rnEcop4qID0gDDjMCv2tVXQVUdznc03d7PfAbdbwGZItI7Idgx5DsAWIscDBqv9w9NqKJSAkwF3gdKFTVw+AEEaBg6HKWEP8JfBXocPfzgBpVDbv7I/E7nwgcB/7LbVr7lYikM4K/a1U9BPwAOIATGGqBtYz877pTT9/tWf2OS/YAITGOjehxvyISAn4PfFFV64Y6P4kkIu8Gjqnq2ujDMU4dad+5D5gH/FxV5wKNjKDmpFjcNvfrgQnAGCAdp3mlq5H2XfflrP69J3uAKAfGRe0XAxVDlJeEExE/TnB4WFWfcA8f7axyuq/Hhip/CXApcJ2I7MNpPrwcp0aR7TZDwMj8zsuBclV93d1/HCdgjOTv+kpgr6oeV9V24AngEkb+d92pp+/2rH7HJXuAWA1Mdkc6BHA6tZ4a4jwlhNv2/gCwTVX/IyrpKeBj7vuPAX8c7Lwliqp+XVWLVbUE57v9m6p+BFgJ3OieNqLKDKCqR4CDIjLVPXQFsJUR/F3jNC0tFpE09996Z5lH9Hcdpafv9ingo+5opsVAbWdT1JlI+pnUInItzl+VXuBBVf3uEGcpIUTkMuDvwCZOtcd/A6cf4jFgPM5/sg+oatcOsGFPREqBr6jqu0VkIk6NIhdYB9ysqq1Dmb94E5E5OB3zAWAP8AmcPwhH7HctIt8BPoQzYm8d8Cmc9vYR9V2LyKNAKc6y3keBO4EnifHdusHypzijnpqAT6jqmjO+V7IHCGOMMbElexOTMcaYHliAMMYYE5MFCGOMMTFZgDDGGBOTBQhjjDExWYAwJgYR+Yf7WiIiH47zZ38j1r2MOdfYMFdjehE9f6If13hVNdJLeoOqhuKRP2MSyWoQxsQgIg3u27uBt4nIevd5A14R+X8istpdX//T7vml7vM2HsGZjIiIPCkia91nFCx3j92Ns+LoehF5OPpe7mzX/+c+z2CTiHwo6rPLop7v8LA7AcqYhPL1fYoxSe0OomoQ7i/6WlVdKCJB4BURec49dxFwgarudff/lzubNRVYLSK/V9U7ROR2VZ0T417vB+bgPL8h371mlZs2F5iJs47OKzjrTL0c/+Iac4rVIIzpn6tw1rZZj7NMSR7Ow1gA3ogKDgBfEJENwGs4C6ZNpneXAY+qakRVjwIvAQujPrtcVTuA9UBJXEpjTC+sBmFM/wjweVV99rSDTl9FY5f9K4GLVbVJRMqAlDP47J5Erx8Uwf7vmkFgNQhjelcPZETtPwt81l06HRGZ4j6Mp6ss4IQbHKbhPOa1U3vn9V2sAj7k9nOMwnkq3BtxKYUxA2B/hRjTu41A2G0qegjnWc8lwJtuR/FxYj/G8q/AZ0RkI7Adp5mp0/3ARhF5011+vNMfgIuBDTgPdfmqqh5xA4wxg86GuRpjjInJmpiMMcbEZAHCGGNMTBYgjDHGxGQBwhhjTEwWIIwxxsRkAcIYY0xMFiCMMcbE9P8BpWit0HFaivsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training progress of light GBM across number of iterations.\n",
    "plot_lgbm_eval_metrics(eval_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>split</th>\n",
       "      <th>split_frac</th>\n",
       "      <th>gain</th>\n",
       "      <th>gain_frac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>target_lag_1</td>\n",
       "      <td>149</td>\n",
       "      <td>4.966667</td>\n",
       "      <td>4.799038e+06</td>\n",
       "      <td>37.018824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>target_item_lag_1</td>\n",
       "      <td>311</td>\n",
       "      <td>10.366667</td>\n",
       "      <td>1.917383e+06</td>\n",
       "      <td>14.790313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>shop_item_mean</td>\n",
       "      <td>148</td>\n",
       "      <td>4.933333</td>\n",
       "      <td>1.541907e+06</td>\n",
       "      <td>11.893961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>shop_mean</td>\n",
       "      <td>235</td>\n",
       "      <td>7.833333</td>\n",
       "      <td>9.853041e+05</td>\n",
       "      <td>7.600439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>item_mean</td>\n",
       "      <td>208</td>\n",
       "      <td>6.933333</td>\n",
       "      <td>8.219406e+05</td>\n",
       "      <td>6.340286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>target_lag_2</td>\n",
       "      <td>55</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>4.593819e+05</td>\n",
       "      <td>3.543580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>target_shop_lag_2</td>\n",
       "      <td>86</td>\n",
       "      <td>2.866667</td>\n",
       "      <td>3.246442e+05</td>\n",
       "      <td>2.504241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>item_category_mean</td>\n",
       "      <td>206</td>\n",
       "      <td>6.866667</td>\n",
       "      <td>2.800450e+05</td>\n",
       "      <td>2.160211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>month</td>\n",
       "      <td>171</td>\n",
       "      <td>5.700000</td>\n",
       "      <td>2.307426e+05</td>\n",
       "      <td>1.779902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>target_item_category_lag_2</td>\n",
       "      <td>126</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>1.929581e+05</td>\n",
       "      <td>1.488440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>target_item_category_lag_1</td>\n",
       "      <td>149</td>\n",
       "      <td>4.966667</td>\n",
       "      <td>1.854168e+05</td>\n",
       "      <td>1.430268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>target_shop_lag_6</td>\n",
       "      <td>22</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>1.700340e+05</td>\n",
       "      <td>1.311608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>target_lag_3</td>\n",
       "      <td>36</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>1.618344e+05</td>\n",
       "      <td>1.248358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>avg_item_price_lag_1</td>\n",
       "      <td>141</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>1.258975e+05</td>\n",
       "      <td>0.971148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>target_shop_lag_1</td>\n",
       "      <td>99</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>1.019474e+05</td>\n",
       "      <td>0.786402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>target_item_lag_2</td>\n",
       "      <td>117</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>9.080095e+04</td>\n",
       "      <td>0.700420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>target_lag_4</td>\n",
       "      <td>17</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>7.618726e+04</td>\n",
       "      <td>0.587693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>target_item_lag_3</td>\n",
       "      <td>63</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>5.681919e+04</td>\n",
       "      <td>0.438292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>target_lag_5</td>\n",
       "      <td>20</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>4.954513e+04</td>\n",
       "      <td>0.382181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>target_shop_lag_12</td>\n",
       "      <td>24</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>3.835406e+04</td>\n",
       "      <td>0.295856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>target_item_category_lag_4</td>\n",
       "      <td>55</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>3.724726e+04</td>\n",
       "      <td>0.287318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>avg_item_price_lag_3</td>\n",
       "      <td>35</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>3.068665e+04</td>\n",
       "      <td>0.236711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>target_item_lag_4</td>\n",
       "      <td>60</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.053719e+04</td>\n",
       "      <td>0.235558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>avg_item_price_lag_2</td>\n",
       "      <td>48</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>2.985530e+04</td>\n",
       "      <td>0.230298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>target_shop_lag_3</td>\n",
       "      <td>29</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>2.740931e+04</td>\n",
       "      <td>0.211430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>target_lag_6</td>\n",
       "      <td>15</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.660903e+04</td>\n",
       "      <td>0.205257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>target_item_lag_12</td>\n",
       "      <td>51</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>2.470429e+04</td>\n",
       "      <td>0.190564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>target_item_category_lag_3</td>\n",
       "      <td>39</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>2.253395e+04</td>\n",
       "      <td>0.173822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>target_item_category_lag_6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>2.144363e+04</td>\n",
       "      <td>0.165412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>target_item_category_lag_5</td>\n",
       "      <td>29</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.516842e+04</td>\n",
       "      <td>0.117006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>target_item_lag_6</td>\n",
       "      <td>40</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.362893e+04</td>\n",
       "      <td>0.105131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>target_item_lag_5</td>\n",
       "      <td>35</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>1.281591e+04</td>\n",
       "      <td>0.098859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>target_shop_lag_4</td>\n",
       "      <td>24</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.179933e+04</td>\n",
       "      <td>0.091018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>target_item_category_lag_12</td>\n",
       "      <td>29</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.064996e+04</td>\n",
       "      <td>0.082152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>target_shop_lag_5</td>\n",
       "      <td>14</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>9.595671e+03</td>\n",
       "      <td>0.074019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>avg_item_price_lag_4</td>\n",
       "      <td>19</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>8.389667e+03</td>\n",
       "      <td>0.064716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>avg_item_price_lag_6</td>\n",
       "      <td>17</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>7.518517e+03</td>\n",
       "      <td>0.057996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>avg_item_price_lag_5</td>\n",
       "      <td>20</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>6.083426e+03</td>\n",
       "      <td>0.046926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>target_lag_12</td>\n",
       "      <td>11</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>4.135123e+03</td>\n",
       "      <td>0.031898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>avg_item_price_lag_12</td>\n",
       "      <td>14</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>2.785476e+03</td>\n",
       "      <td>0.021487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        feature  split  split_frac          gain  gain_frac\n",
       "1                  target_lag_1    149    4.966667  4.799038e+06  37.018824\n",
       "3             target_item_lag_1    311   10.366667  1.917383e+06  14.790313\n",
       "37               shop_item_mean    148    4.933333  1.541907e+06  11.893961\n",
       "35                    shop_mean    235    7.833333  9.853041e+05   7.600439\n",
       "36                    item_mean    208    6.933333  8.219406e+05   6.340286\n",
       "6                  target_lag_2     55    1.833333  4.593819e+05   3.543580\n",
       "7             target_shop_lag_2     86    2.866667  3.246442e+05   2.504241\n",
       "38           item_category_mean    206    6.866667  2.800450e+05   2.160211\n",
       "39                        month    171    5.700000  2.307426e+05   1.779902\n",
       "9    target_item_category_lag_2    126    4.200000  1.929581e+05   1.488440\n",
       "4    target_item_category_lag_1    149    4.966667  1.854168e+05   1.430268\n",
       "27            target_shop_lag_6     22    0.733333  1.700340e+05   1.311608\n",
       "11                 target_lag_3     36    1.200000  1.618344e+05   1.248358\n",
       "0          avg_item_price_lag_1    141    4.700000  1.258975e+05   0.971148\n",
       "2             target_shop_lag_1     99    3.300000  1.019474e+05   0.786402\n",
       "8             target_item_lag_2    117    3.900000  9.080095e+04   0.700420\n",
       "16                 target_lag_4     17    0.566667  7.618726e+04   0.587693\n",
       "13            target_item_lag_3     63    2.100000  5.681919e+04   0.438292\n",
       "21                 target_lag_5     20    0.666667  4.954513e+04   0.382181\n",
       "32           target_shop_lag_12     24    0.800000  3.835406e+04   0.295856\n",
       "19   target_item_category_lag_4     55    1.833333  3.724726e+04   0.287318\n",
       "10         avg_item_price_lag_3     35    1.166667  3.068665e+04   0.236711\n",
       "18            target_item_lag_4     60    2.000000  3.053719e+04   0.235558\n",
       "5          avg_item_price_lag_2     48    1.600000  2.985530e+04   0.230298\n",
       "12            target_shop_lag_3     29    0.966667  2.740931e+04   0.211430\n",
       "26                 target_lag_6     15    0.500000  2.660903e+04   0.205257\n",
       "33           target_item_lag_12     51    1.700000  2.470429e+04   0.190564\n",
       "14   target_item_category_lag_3     39    1.300000  2.253395e+04   0.173822\n",
       "29   target_item_category_lag_6     33    1.100000  2.144363e+04   0.165412\n",
       "24   target_item_category_lag_5     29    0.966667  1.516842e+04   0.117006\n",
       "28            target_item_lag_6     40    1.333333  1.362893e+04   0.105131\n",
       "23            target_item_lag_5     35    1.166667  1.281591e+04   0.098859\n",
       "17            target_shop_lag_4     24    0.800000  1.179933e+04   0.091018\n",
       "34  target_item_category_lag_12     29    0.966667  1.064996e+04   0.082152\n",
       "22            target_shop_lag_5     14    0.466667  9.595671e+03   0.074019\n",
       "15         avg_item_price_lag_4     19    0.633333  8.389667e+03   0.064716\n",
       "25         avg_item_price_lag_6     17    0.566667  7.518517e+03   0.057996\n",
       "20         avg_item_price_lag_5     20    0.666667  6.083426e+03   0.046926\n",
       "31                target_lag_12     11    0.366667  4.135123e+03   0.031898\n",
       "30        avg_item_price_lag_12     14    0.466667  2.785476e+03   0.021487"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show variable importance.\n",
    "show_lgbm_var_imp(lgbm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on training and validation set.\n",
    "Z_train_lgbm = lgbm_model.predict(train_df[lgbm_features])\n",
    "Z_valid_lgbm = lgbm_model.predict(valid_df[lgbm_features]).clip(0,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute performance on training and validation set.\n",
    "compute_reg_score(Y_train, Z_train_lgbm)\n",
    "print('-'*100)\n",
    "compute_reg_score(Y_valid, Z_valid_lgbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with linear model using all features.  We will use elastic net with some parameters, and fine tune later.\n",
    "lr_features = ['avg_item_price_lag_1', 'target_lag_1', 'target_shop_lag_1', 'target_item_lag_1', \n",
    "                 'target_item_category_lag_1', 'avg_item_price_lag_2', 'target_lag_2', 'target_shop_lag_2',\n",
    "                 'target_item_lag_2', 'target_item_category_lag_2', 'avg_item_price_lag_3', 'target_lag_3', \n",
    "                 'target_shop_lag_3', 'target_item_lag_3', 'target_item_category_lag_3', 'avg_item_price_lag_4', \n",
    "                 'target_lag_4', 'target_shop_lag_4', 'target_item_lag_4', 'target_item_category_lag_4',\n",
    "                 'avg_item_price_lag_5', 'target_lag_5', 'target_shop_lag_5', 'target_item_lag_5', \n",
    "                 'target_item_category_lag_5', 'avg_item_price_lag_6', 'target_lag_6', 'target_shop_lag_6',\n",
    "                 'target_item_lag_6', 'target_item_category_lag_6', 'avg_item_price_lag_12', 'target_lag_12', \n",
    "                 'target_shop_lag_12', 'target_item_lag_12', 'target_item_category_lag_12', 'shop_mean',\n",
    "                 'item_mean', 'shop_item_mean', 'item_category_mean', 'month']\n",
    "#lr_model = LinearRegression(normalize=True, n_jobs=-1)\n",
    "lr_model = ElasticNet(normalize=True, alpha=1e-8, l1_ratio=0.1)\n",
    "lr_model.fit(train_df[lr_features], Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on training and validation set.\n",
    "Z_train_lr = lr_model.predict(train_df[lr_features])\n",
    "Z_valid_lr = lr_model.predict(valid_df[lr_features]).clip(0,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute performance on training and validation set.\n",
    "compute_reg_score(Y_train, Z_train_lr)\n",
    "print('-'*100)\n",
    "compute_reg_score(Y_valid, Z_valid_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's examine the coeeficients estimated by elastic net.\n",
    "beta = lr_model.coef_\n",
    "beta = pd.Series(beta, index=lr_features)\n",
    "beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beta coefficients are all non-zeros.  We will need to tune elastic net to do feature selection for linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do cross-validation to tune elastic net.\n",
    "# Prepare cross validation data.\n",
    "test_fold = np.full(train_df.shape[0], -1, dtype=np.int8)\n",
    "sel = train_df['date_block_num']>=25 #use 25,26,27 as validation set when tuning elastic net\n",
    "test_fold[sel] = 0    \n",
    "ps = PredefinedSplit(test_fold=test_fold)\n",
    "# Base params\n",
    "max_iter = 1000\n",
    "alphas = None\n",
    "#alphas = [.1, .2, .3, .4, .5, .6, .7, .8, .9, 1]\n",
    "n_alphas = 10\n",
    "#l1_ratio = [.1, .3, .5, .7, .9, .95, .99, 1]\n",
    "l1_ratio = [.1, .5, 1]\n",
    "ecv_params = {'cv': ps, 'random_state': 0, # Changing this could do ensembling options    \n",
    "              'alphas': alphas, 'n_alphas': n_alphas, 'l1_ratio': l1_ratio,\n",
    "              'eps': 0.001, 'tol': 0.0001, 'max_iter': max_iter, 'fit_intercept': True, 'normalize': True, \n",
    "              'positive': False, 'selection': 'random', 'verbose': 2, 'n_jobs': -1\n",
    "             }\n",
    "# Tune\n",
    "ecv = ElasticNetCV()\n",
    "ecv = ecv.set_params(**ecv_params)\n",
    "ecv = ecv.fit(train_df[lr_features], Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best parameter from ElasticNetCV.\n",
    "best_params = (ecv.alpha_, ecv.l1_ratio_, ecv.n_iter_)\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the corresponding elastic net coefficients.\n",
    "beta = pd.Series(ecv.coef_, index=lr_features)\n",
    "beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize the magnitude of coefficients estimated by the best elastic net model.\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "sel = np.abs(beta)>0.01\n",
    "beta[sel].plot.bar()\n",
    "plt.xticks(rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions from the best elastic net model.\n",
    "Z_train_ecv = ecv.predict(train_df[lr_features])\n",
    "Z_valid_ecv = ecv.predict(valid_df[lr_features]).clip(0,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute performance of the best elastic net model.\n",
    "compute_reg_score(Y_train, Z_train_ecv)\n",
    "print('-'*100)\n",
    "compute_reg_score(Y_valid, Z_valid_ecv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance is comparable to the model without fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will retrain linear model on the training data using features selected by the best elastic net model only.\n",
    "lr_features = ['target_lag_1', 'target_lag_2', 'target_lag_3', 'target_lag_4', 'target_lag_5', 'target_lag_6', \n",
    "               'shop_mean', 'item_mean', 'shop_item_mean', 'item_category_mean']\n",
    "lr_model = LinearRegression(normalize=True, n_jobs=-1)\n",
    "lr_model.fit(train_df[lr_features], Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's examine the estimated coefficients.\n",
    "beta = lr_model.coef_\n",
    "beta = pd.Series(beta, index=lr_features)\n",
    "beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on training and validation set.\n",
    "Z_train_lr = lr_model.predict(train_df[lr_features])\n",
    "Z_valid_lr = lr_model.predict(valid_df[lr_features]).clip(0,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute performance on training and validation set.\n",
    "compute_reg_score(Y_train, Z_train_lr)\n",
    "print('-'*100)\n",
    "compute_reg_score(Y_valid, Z_valid_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will combine predictions from light GBM and linear model. First, check that the two set of predictions are not overly correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(Z_valid_lgbm, Z_valid_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# They are somewhat correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted Averaging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a simple convex combination to combine the two set of predictions.  We will find the optimal combination coefficient alpha using grid search on the range of alphas_to_try.  The best alpha should have the lowest RMSE on the validation predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas_to_try = np.linspace(0, 1, 1001)\n",
    "\n",
    "best_alpha = 0 \n",
    "rmse_train_simple_mix = np.inf \n",
    "for alpha in alphas_to_try:\n",
    "    Z_mix = alpha*Z_valid_lgbm + (1 - alpha)*Z_valid_lr\n",
    "    rmse = np.sqrt(mean_squared_error(Y_valid, Z_mix)) \n",
    "    if rmse<rmse_train_simple_mix:\n",
    "        best_alpha = alpha\n",
    "        rmse_train_simple_mix = rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute performance of the best combined validation prediction.\n",
    "Z_mix = best_alpha*Z_valid_lgbm + (1 - best_alpha)*Z_valid_lr\n",
    "compute_reg_score(Y_valid, Z_mix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
