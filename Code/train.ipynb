{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pickle, sys, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import lightgbm as lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy 1.18.1\n",
      "pandas 1.0.1\n",
      "sklearn 0.22.1\n",
      "lightgbm 2.3.1\n"
     ]
    }
   ],
   "source": [
    "for p in [np, pd, sklearn, lgbm]:\n",
    "    print (p.__name__, p.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and validation data.  \n",
    "train_df = pd.read_hdf('../CleanData/trainDF.h5', 'df')\n",
    "valid_df = pd.read_hdf('../CleanData/validDF.h5', 'df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the training and validation data.  This constitues all the data available for training.\n",
    "train_valid_df = pd.concat([train_df, valid_df], ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single out the target variable.\n",
    "Y_valid = valid_df['target']\n",
    "Y_train_valid = train_valid_df['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Light GBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train light GBM on the entire training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttrain's rmse: 1.10888\tvalid's rmse: 1.02024\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's rmse: 1.04434\tvalid's rmse: 0.967287\n",
      "[3]\ttrain's rmse: 0.999699\tvalid's rmse: 0.930433\n",
      "[4]\ttrain's rmse: 0.968809\tvalid's rmse: 0.904698\n",
      "[5]\ttrain's rmse: 0.935099\tvalid's rmse: 0.877754\n",
      "[6]\ttrain's rmse: 0.919503\tvalid's rmse: 0.865431\n",
      "[7]\ttrain's rmse: 0.895009\tvalid's rmse: 0.844792\n",
      "[8]\ttrain's rmse: 0.881292\tvalid's rmse: 0.832516\n",
      "[9]\ttrain's rmse: 0.869861\tvalid's rmse: 0.822814\n",
      "[10]\ttrain's rmse: 0.863269\tvalid's rmse: 0.816816\n",
      "[11]\ttrain's rmse: 0.855875\tvalid's rmse: 0.810763\n",
      "[12]\ttrain's rmse: 0.850413\tvalid's rmse: 0.806096\n",
      "[13]\ttrain's rmse: 0.847366\tvalid's rmse: 0.803608\n",
      "[14]\ttrain's rmse: 0.843692\tvalid's rmse: 0.801739\n",
      "[15]\ttrain's rmse: 0.841116\tvalid's rmse: 0.799824\n",
      "[16]\ttrain's rmse: 0.838802\tvalid's rmse: 0.797982\n",
      "[17]\ttrain's rmse: 0.83049\tvalid's rmse: 0.791654\n",
      "[18]\ttrain's rmse: 0.828784\tvalid's rmse: 0.790664\n",
      "[19]\ttrain's rmse: 0.82424\tvalid's rmse: 0.786975\n",
      "[20]\ttrain's rmse: 0.819048\tvalid's rmse: 0.78296\n",
      "[21]\ttrain's rmse: 0.816879\tvalid's rmse: 0.782461\n",
      "[22]\ttrain's rmse: 0.815986\tvalid's rmse: 0.781782\n",
      "[23]\ttrain's rmse: 0.814462\tvalid's rmse: 0.78107\n",
      "[24]\ttrain's rmse: 0.811878\tvalid's rmse: 0.778583\n",
      "[25]\ttrain's rmse: 0.808627\tvalid's rmse: 0.775997\n",
      "[26]\ttrain's rmse: 0.807413\tvalid's rmse: 0.775755\n",
      "[27]\ttrain's rmse: 0.806738\tvalid's rmse: 0.775335\n",
      "[28]\ttrain's rmse: 0.805065\tvalid's rmse: 0.773583\n",
      "[29]\ttrain's rmse: 0.804434\tvalid's rmse: 0.773143\n",
      "[30]\ttrain's rmse: 0.80381\tvalid's rmse: 0.772735\n",
      "[31]\ttrain's rmse: 0.802918\tvalid's rmse: 0.771987\n",
      "[32]\ttrain's rmse: 0.802399\tvalid's rmse: 0.771487\n",
      "[33]\ttrain's rmse: 0.80174\tvalid's rmse: 0.771025\n",
      "[34]\ttrain's rmse: 0.799683\tvalid's rmse: 0.769686\n",
      "[35]\ttrain's rmse: 0.799146\tvalid's rmse: 0.768904\n",
      "[36]\ttrain's rmse: 0.798743\tvalid's rmse: 0.768662\n",
      "[37]\ttrain's rmse: 0.798142\tvalid's rmse: 0.768352\n",
      "[38]\ttrain's rmse: 0.797592\tvalid's rmse: 0.768004\n",
      "[39]\ttrain's rmse: 0.79664\tvalid's rmse: 0.767673\n",
      "[40]\ttrain's rmse: 0.795889\tvalid's rmse: 0.766986\n",
      "[41]\ttrain's rmse: 0.795617\tvalid's rmse: 0.766717\n",
      "[42]\ttrain's rmse: 0.794768\tvalid's rmse: 0.766356\n",
      "[43]\ttrain's rmse: 0.793888\tvalid's rmse: 0.765596\n",
      "[44]\ttrain's rmse: 0.790919\tvalid's rmse: 0.763319\n",
      "[45]\ttrain's rmse: 0.790366\tvalid's rmse: 0.762526\n",
      "[46]\ttrain's rmse: 0.789184\tvalid's rmse: 0.761972\n",
      "[47]\ttrain's rmse: 0.788444\tvalid's rmse: 0.761257\n",
      "[48]\ttrain's rmse: 0.78702\tvalid's rmse: 0.760349\n",
      "[49]\ttrain's rmse: 0.786503\tvalid's rmse: 0.759872\n",
      "[50]\ttrain's rmse: 0.785496\tvalid's rmse: 0.759307\n",
      "[51]\ttrain's rmse: 0.785274\tvalid's rmse: 0.758902\n",
      "[52]\ttrain's rmse: 0.785124\tvalid's rmse: 0.758772\n",
      "[53]\ttrain's rmse: 0.784825\tvalid's rmse: 0.758604\n",
      "[54]\ttrain's rmse: 0.784342\tvalid's rmse: 0.758006\n",
      "[55]\ttrain's rmse: 0.783932\tvalid's rmse: 0.757699\n",
      "[56]\ttrain's rmse: 0.783657\tvalid's rmse: 0.757532\n",
      "[57]\ttrain's rmse: 0.783382\tvalid's rmse: 0.757452\n",
      "[58]\ttrain's rmse: 0.783014\tvalid's rmse: 0.757353\n",
      "[59]\ttrain's rmse: 0.782559\tvalid's rmse: 0.757052\n",
      "[60]\ttrain's rmse: 0.782306\tvalid's rmse: 0.756633\n",
      "[61]\ttrain's rmse: 0.780282\tvalid's rmse: 0.755167\n",
      "[62]\ttrain's rmse: 0.779522\tvalid's rmse: 0.754786\n",
      "[63]\ttrain's rmse: 0.779171\tvalid's rmse: 0.754644\n",
      "[64]\ttrain's rmse: 0.778519\tvalid's rmse: 0.754032\n",
      "[65]\ttrain's rmse: 0.77836\tvalid's rmse: 0.753791\n",
      "[66]\ttrain's rmse: 0.777992\tvalid's rmse: 0.75355\n",
      "[67]\ttrain's rmse: 0.777744\tvalid's rmse: 0.753239\n",
      "[68]\ttrain's rmse: 0.777471\tvalid's rmse: 0.753071\n",
      "[69]\ttrain's rmse: 0.777082\tvalid's rmse: 0.752958\n",
      "[70]\ttrain's rmse: 0.776721\tvalid's rmse: 0.752782\n",
      "[71]\ttrain's rmse: 0.776485\tvalid's rmse: 0.752592\n",
      "[72]\ttrain's rmse: 0.776219\tvalid's rmse: 0.752384\n",
      "[73]\ttrain's rmse: 0.774646\tvalid's rmse: 0.751369\n",
      "[74]\ttrain's rmse: 0.773989\tvalid's rmse: 0.750906\n",
      "[75]\ttrain's rmse: 0.773781\tvalid's rmse: 0.750876\n",
      "[76]\ttrain's rmse: 0.773134\tvalid's rmse: 0.750586\n",
      "[77]\ttrain's rmse: 0.772743\tvalid's rmse: 0.750203\n",
      "[78]\ttrain's rmse: 0.772603\tvalid's rmse: 0.750079\n",
      "[79]\ttrain's rmse: 0.772305\tvalid's rmse: 0.749989\n",
      "[80]\ttrain's rmse: 0.771578\tvalid's rmse: 0.749818\n",
      "[81]\ttrain's rmse: 0.771234\tvalid's rmse: 0.749499\n",
      "[82]\ttrain's rmse: 0.770975\tvalid's rmse: 0.74915\n",
      "[83]\ttrain's rmse: 0.770656\tvalid's rmse: 0.748732\n",
      "[84]\ttrain's rmse: 0.770446\tvalid's rmse: 0.748497\n",
      "[85]\ttrain's rmse: 0.770051\tvalid's rmse: 0.748016\n",
      "[86]\ttrain's rmse: 0.769743\tvalid's rmse: 0.747889\n",
      "[87]\ttrain's rmse: 0.769638\tvalid's rmse: 0.747735\n",
      "[88]\ttrain's rmse: 0.769407\tvalid's rmse: 0.747666\n",
      "[89]\ttrain's rmse: 0.769195\tvalid's rmse: 0.747354\n",
      "[90]\ttrain's rmse: 0.768767\tvalid's rmse: 0.747154\n",
      "[91]\ttrain's rmse: 0.768328\tvalid's rmse: 0.746739\n",
      "[92]\ttrain's rmse: 0.768244\tvalid's rmse: 0.746625\n",
      "[93]\ttrain's rmse: 0.768165\tvalid's rmse: 0.746537\n",
      "[94]\ttrain's rmse: 0.767102\tvalid's rmse: 0.745877\n",
      "[95]\ttrain's rmse: 0.766744\tvalid's rmse: 0.7455\n",
      "[96]\ttrain's rmse: 0.766552\tvalid's rmse: 0.745318\n",
      "[97]\ttrain's rmse: 0.766456\tvalid's rmse: 0.745283\n",
      "[98]\ttrain's rmse: 0.766302\tvalid's rmse: 0.745114\n",
      "[99]\ttrain's rmse: 0.766129\tvalid's rmse: 0.744911\n",
      "[100]\ttrain's rmse: 0.765892\tvalid's rmse: 0.744664\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's rmse: 0.765892\tvalid's rmse: 0.744664\n",
      "62.577625036239624\n"
     ]
    }
   ],
   "source": [
    "# Retrain on the entire training and validation set, and make prediction on test set. \n",
    "lgbm_features = ['avg_item_price_lag_1', 'target_lag_1', 'target_shop_lag_1', 'target_item_lag_1', \n",
    "                 'target_item_category_lag_1', 'avg_item_price_lag_2', 'target_lag_2', 'target_shop_lag_2',\n",
    "                 'target_item_lag_2', 'target_item_category_lag_2', 'avg_item_price_lag_3', 'target_lag_3', \n",
    "                 'target_shop_lag_3', 'target_item_lag_3', 'target_item_category_lag_3', 'avg_item_price_lag_4', \n",
    "                 'target_lag_4', 'target_shop_lag_4', 'target_item_lag_4', 'target_item_category_lag_4',\n",
    "                 'avg_item_price_lag_5', 'target_lag_5', 'target_shop_lag_5', 'target_item_lag_5', \n",
    "                 'target_item_category_lag_5', 'avg_item_price_lag_6', 'target_lag_6', 'target_shop_lag_6',\n",
    "                 'target_item_lag_6', 'target_item_category_lag_6', 'avg_item_price_lag_12', 'target_lag_12', \n",
    "                 'target_shop_lag_12', 'target_item_lag_12', 'target_item_category_lag_12', 'shop_mean',\n",
    "                 'item_mean', 'shop_item_mean', 'item_category_mean', 'month']\n",
    "lgbm_train_data = lgbm.Dataset(train_valid_df[lgbm_features], label=Y_train_valid, feature_name=lgbm_features) #categorical_feature\n",
    "lgbm_valid_data = lgbm.Dataset(valid_df[lgbm_features], label=Y_valid, feature_name=lgbm_features)\n",
    "\n",
    "params = {'objective':'regression', 'metric':['rmse'], 'boosting_type':'gbdt', 'num_rounds':100, 'eta':0.2, \n",
    "          'max_depth':5, 'min_data_in_leaf':150, 'min_gain_to_split':0.01, \n",
    "          'feature_fraction':0.7, 'bagging_freq':0, 'bagging_fraction':1.0, 'lambda_l1':0,\n",
    "          'lambda_l2':0.001, 'early_stopping_round':20, 'verbosity':1}\n",
    "eval_metrics_full = {}\n",
    "start = time.time()\n",
    "lgbm_model_full = lgbm.train(params, lgbm_train_data, valid_sets=[lgbm_train_data, lgbm_valid_data],\n",
    "                             valid_names=['train', 'valid'], evals_result=eval_metrics_full, verbose_eval=True)\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model.\n",
    "filename = \"../Model/lgbm_model_full.pkl\"\n",
    "with open(filename, 'wb') as file:\n",
    "    pickle.dump(lgbm_model_full, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train linear model on the entire training data, using featurees selected by ElasticNetCV only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrain on the entire training and validation set, and make prediction on test set. \n",
    "lr_features = ['target_lag_1', 'target_lag_2', 'target_lag_3', 'target_lag_4', 'target_lag_5', 'target_lag_6', \n",
    "               'shop_mean', 'item_mean', 'shop_item_mean', 'item_category_mean']\n",
    "lr_model_full = LinearRegression(normalize=True, n_jobs=-1)\n",
    "lr_model_full.fit(train_valid_df[lr_features], Y_train_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model.\n",
    "filename = \"../Model/lr_model_full.pkl\"\n",
    "with open(filename, 'wb') as file:\n",
    "    pickle.dump(lr_model_full, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
